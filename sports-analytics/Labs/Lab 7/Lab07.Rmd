---
title: 'Lab07'
author: "Shane Fuller"
date: "Fall 2019"
output:
  html_document:
    df_print: paged
---


## Overview

In this lab, we'll return to the NHL play by play data set, containing shots from the 20172018 and 20182019 seasons.

```{r, eval = FALSE}

library(RCurl); library(tidyverse)
gURL <- "https://raw.githubusercontent.com/statsbylopez/StatsSports/master/Data/pbp_data_hockey.rds"
pbp_data <- readRDS(gzcon(url(gURL)))
names(pbp_data)

pbp_data <- pbp_data %>% 
  mutate(coords_x_adj = ifelse(event_team == home_team, 
                               -1*abs(coords_x), abs(coords_x)), 
         coords_y_adj = ifelse(event_team == home_team & coords_x < 0, 
                               coords_y, -1*coords_y), 
         coords_y_adj = ifelse(event_team == away_team & coords_x > 0, 
                               coords_y, -1*coords_y))

head(pbp_data)
```


## Mapping shots

Let's take a sample game, between Detroit and Edmonton in the 20182019 season. In this game, we can use the `count` command to identify the frequency with which each team shot the puck. Turns out, Edmonton had 20 more shots than Detroit. 

```{r, eval = FALSE}
sample_game <- pbp_data %>% filter(game_id == 2018020197)
sample_game %>% count(event_team)
```

Returning to the idea of mapping

```{r, eval = FALSE}
ggplot(sample_game, aes(x = coords_x_adj, y = coords_y_adj, 
                        colour = event_team, pch = event_type)) + 
  geom_point()
```

One approach for improving the map above is to allow for different shapes or colorsbased on the type of shot (`event_type`)

```{r, eval = FALSE}
ggplot(sample_game, aes(x = coords_x_adj, y = coords_y_adj, 
                        colour = event_team)) + 
  geom_point()

ggplot(sample_game, aes(x = coords_x_adj, y = coords_y_adj, 
                        colour = event_type)) + 
  geom_point()
```

1. What do the location maps above provide that the general shot map does not? Be specific .

*The location maps above provide a much better depiction of the types of shots that are happening, and who they are happening from. For examples, the models shown here that have different colors based on team or shot type, or the maps that show different shapes to display different information provide a much better narrative as to what is actively happening in the sport. Furthermore, these maps are much more useful to anyone who is attempting to derive valuable information about how to improve a teams performance.*

## Logistic regression modeling

We can try a few logistic regression models

```{r, eval = FALSE}
library(broom)
pbp_data <- pbp_data %>% 
  mutate(is_home = event_team == home_team)

fit_1 <- glm(event_type == "GOAL" ~ event_distance + 
               event_angle + event_detail ,
             family = "binomial", data = pbp_data)
tidy(fit_1)

fit_2 <- glm(event_type == "GOAL" ~ is_home, data = pbp_data, 
          family = "binomial")
tidy(fit_2)

fit_3 <- glm(event_type == "GOAL" ~ event_distance + 
               event_angle + event_detail + is_home, data = pbp_data, 
          family = "binomial")
tidy(fit_3)
```

2. What is the difference between `fit_1` and `fit_2`.

*Fit_1 is a logistic model measuring goals as a function of the shot distance, the shot angle, and the shot type, while Fit_2 is a logistic model measuring goals as a function of whether or not the shot came from the home or away team.*

3. Interpret the coefficient on `is_home` in `fit_2`. What does this entail about shooting the puck at home?

```{r}
exp(0.05328478)
```


*The odds of a shot taken at home are 5.5% more likely to go in over shots that are taken when away.*

4. Interpret the coefficient on `is_home` in `fit_3`. What does this entail about shooting the puck at home?

```{r}
exp(0.02589726)
```

*The odds of a shot taken at home are 2.6% more likely to in over shots that are taken when away, given that the shot angle and shot detail are in the model.*

5. Provide one possible explanation for your findings above.

*The concept that the shot would be more likely to go in when at home makes sense, as the players often play better when their is a home crowd behind then, and they are playing in their own arena. However, the idea that the shots taken at home had a greater impact on Fit_2 than in Fit_3 would come down to the variables than are included in each model. Fit_2 only had the is_home variable in its model, therefore it would make sense that it would treat the singular variable with weight than how it was treated in Fit_3.*

## Hosmer Lemeshow

We'll use the Hosmer Lemeshow test -- review your notes from last class -- as one approach to assess the fits above. Specifically, we create the goal probability `shot_prob_fit_3` as the predicted goal likelihood. 

```{r, eval = FALSE}
pbp_data$shot_prob_fit_3 <- predict(fit_3, pbp_data, type = "response")

tab_check <- pbp_data %>% 
  filter(!is.na(shot_prob_fit_3)) %>% 
  mutate(shot_prob_cat = cut(shot_prob_fit_3, 10)) %>% 
  group_by(shot_prob_cat) %>% 
  summarise(ave_exp_goals = sum(shot_prob), 
            ave_act_goals = sum(event_type == "GOAL"), 
            n_shots = n())

tab_check <- tab_check %>% 
  mutate(diff_sq = (ave_exp_goals - ave_act_goals)^2/
           ((ave_exp_goals)*(1-ave_exp_goals/n_shots)))

tab_check
```


6. Descrive the distribution between observed and expected goals in the ten bins above. Where does the model tend to fit well? Where are there more goals than expected? Where are there less goals than expected?

*The model seems to fit best for bins 5, 6, and 10, where the average expected goals and average actual goals are very similar. The bins that seemed to perform the worst would include bins 3 and 4, which both appear to be a few 100 off in expected goals versus average goals. The distribution of over and under estimating is also interesting, as the model first over estimates for the first bin, then under estimates in bins in bins 2 through 4, and then continues to over estimate throughout the rest of the model.*

## Hosmer Lemeshow

```{r, eval = FALSE}
hm_test <- tab_check %>% 
  summarise(test_stat = sum(diff_sq))
hm_test

1-pchisq(hm_test$test_stat, df = 8, lower.tail = TRUE)
```

7. State the null and alternative hypotheses for the HL test. Would we reject or fail to reject the null hypothesis? What does this say about `fit_3`? 

*The null hypothesis would state that there is no lack of fit in Fit_3, and the alternative hypothesis would state that there is a lack of fit in the model, or that the probabilities do not reflect reality. Here, we would reject the null hypothesis. This would suggest that Fit_3 is not the best model at predicting goals.*
